{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'macOS-12.6-arm64-arm-64bit'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import platform\n",
    "platform.platform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages (1.11.0)\n",
      "Requirement already satisfied: torchvision in /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages (0.12.0a0)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-0.12.1-cp310-cp310-macosx_11_0_arm64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages (from torch) (4.2.0)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages (from torchvision) (2.27.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages (from torchvision) (9.1.1)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages (from torchvision) (1.22.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages (from requests->torchvision) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages (from requests->torchvision) (2022.5.18.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages (from requests->torchvision) (1.26.9)\n",
      "Installing collected packages: torchaudio\n",
      "Successfully installed torchaudio-0.12.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-2.6.1-py3-none-any.whl (441 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m441.9/441.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting transformers\n",
      "  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface_hub\n",
      "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multiprocess\n",
      "  Downloading multiprocess-0.70.13-py310-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages (from datasets) (6.0)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.3-cp310-cp310-macosx_11_0_arm64.whl (336 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.4/336.4 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages (from datasets) (1.22.4)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages (from datasets) (21.3)\n",
      "Collecting pyarrow>=6.0.0\n",
      "  Downloading pyarrow-9.0.0-cp310-cp310-macosx_11_0_arm64.whl (21.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.6/21.6 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages (from datasets) (2.27.1)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages (from datasets) (1.4.2)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.1.0-cp310-cp310-macosx_11_0_arm64.whl (31 kB)\n",
      "Collecting fsspec[http]>=2021.11.1\n",
      "  Downloading fsspec-2022.10.0-py3-none-any.whl (138 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.8/138.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dill<0.3.6\n",
      "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.8/95.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages (from datasets) (4.64.0)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.8.0-py3-none-any.whl (10 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.9.13-cp310-cp310-macosx_11_0_arm64.whl (287 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.1-cp310-cp310-macosx_12_0_arm64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages (from huggingface_hub) (4.2.0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.1-cp310-cp310-macosx_11_0_arm64.whl (34 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp310-cp310-macosx_11_0_arm64.whl (29 kB)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages (from aiohttp->datasets) (2.0.12)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.1-cp310-cp310-macosx_11_0_arm64.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2022.5.18.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: tokenizers, xxhash, regex, pyarrow, multidict, fsspec, frozenlist, filelock, dill, async-timeout, yarl, responses, multiprocess, huggingface_hub, aiosignal, transformers, aiohttp, datasets\n",
      "Successfully installed aiohttp-3.8.3 aiosignal-1.2.0 async-timeout-4.0.2 datasets-2.6.1 dill-0.3.5.1 filelock-3.8.0 frozenlist-1.3.1 fsspec-2022.10.0 huggingface_hub-0.10.1 multidict-6.0.2 multiprocess-0.70.13 pyarrow-9.0.0 regex-2022.9.13 responses-0.18.0 tokenizers-0.13.1 transformers-4.23.1 xxhash-3.1.0 yarl-1.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets transformers huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/Users/curtispond/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa7001ac1044fdba815309571c60d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Load the IMDB datase\n",
    "from datasets import load_dataset\n",
    "imdb = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create smaller training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMBD is huge, so the recommendation is to create smaller train and test datasets\n",
    "small_train_dataset = imdb[\"train\"].shuffle(seed=42).select([i for i in list(range(3000))])\n",
    "small_test_dataset = imdb[\"test\"].shuffle(seed=42).select([i for i in list(range(300))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use DistilBERT tokenizer to preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2bc84573dc24bbeb36d77c70526cbbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb1be801d884b8eb3c27f65bd6665c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a0a6e03112a4547b8c033fcf4f751f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e6c661f0084a348b51e53051a1770c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ca35b69497d4585960c481e1410a889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4834264e834a0aad007e4eeb8ccfb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "tokenized_train = small_train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_test = small_test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To speed up training, use a data_collator to convert training samples to PyTorch tensors and \n",
    "# concatenate them with the correct amount of padding\n",
    "\n",
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ede6187da34faebbf603518ae3e862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the metrics needed to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    " \n",
    "def compute_metrics(eval_pred):\n",
    "   load_accuracy = load_metric(\"accuracy\")\n",
    "   load_f1 = load_metric(\"f1\")\n",
    "  \n",
    "   logits, labels = eval_pred\n",
    "   predictions = np.argmax(logits, axis=-1)\n",
    "   accuracy = load_accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "   f1 = load_f1.compute(predictions=predictions, references=labels)[\"f1\"]\n",
    "   return {\"accuracy\": accuracy, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Token is required (`use_auth_token=True`), but no token found. You need to provide a token or be logged in to Hugging Face with `huggingface-cli login` or `notebook_login`. See https://huggingface.co/settings/tokens.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/curtispond/Documents/huggingface/huggingface-playground/sentiment-analysis/sentiment-analysis.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/curtispond/Documents/huggingface/huggingface-playground/sentiment-analysis/sentiment-analysis.ipynb#X64sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m repo_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfinetuning-sentiment-model-3000-samples\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/curtispond/Documents/huggingface/huggingface-playground/sentiment-analysis/sentiment-analysis.ipynb#X64sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m training_args \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/curtispond/Documents/huggingface/huggingface-playground/sentiment-analysis/sentiment-analysis.ipynb#X64sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m    output_dir\u001b[39m=\u001b[39mrepo_name,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/curtispond/Documents/huggingface/huggingface-playground/sentiment-analysis/sentiment-analysis.ipynb#X64sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m    learning_rate\u001b[39m=\u001b[39m\u001b[39m2e-5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/curtispond/Documents/huggingface/huggingface-playground/sentiment-analysis/sentiment-analysis.ipynb#X64sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m    push_to_hub\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/curtispond/Documents/huggingface/huggingface-playground/sentiment-analysis/sentiment-analysis.ipynb#X64sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/curtispond/Documents/huggingface/huggingface-playground/sentiment-analysis/sentiment-analysis.ipynb#X64sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/curtispond/Documents/huggingface/huggingface-playground/sentiment-analysis/sentiment-analysis.ipynb#X64sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m    model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/curtispond/Documents/huggingface/huggingface-playground/sentiment-analysis/sentiment-analysis.ipynb#X64sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m    args\u001b[39m=\u001b[39;49mtraining_args,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/curtispond/Documents/huggingface/huggingface-playground/sentiment-analysis/sentiment-analysis.ipynb#X64sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m    train_dataset\u001b[39m=\u001b[39;49mtokenized_train,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/curtispond/Documents/huggingface/huggingface-playground/sentiment-analysis/sentiment-analysis.ipynb#X64sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m    eval_dataset\u001b[39m=\u001b[39;49mtokenized_test,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/curtispond/Documents/huggingface/huggingface-playground/sentiment-analysis/sentiment-analysis.ipynb#X64sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m    tokenizer\u001b[39m=\u001b[39;49mtokenizer,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/curtispond/Documents/huggingface/huggingface-playground/sentiment-analysis/sentiment-analysis.ipynb#X64sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m    data_collator\u001b[39m=\u001b[39;49mdata_collator,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/curtispond/Documents/huggingface/huggingface-playground/sentiment-analysis/sentiment-analysis.ipynb#X64sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m    compute_metrics\u001b[39m=\u001b[39;49mcompute_metrics,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/curtispond/Documents/huggingface/huggingface-playground/sentiment-analysis/sentiment-analysis.ipynb#X64sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages/transformers/trainer.py:489\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[39m# Create clone of distant repo and output directory if needed\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpush_to_hub:\n\u001b[0;32m--> 489\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit_git_repo(at_init\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    490\u001b[0m     \u001b[39m# In case of pull, we need to make sure every process has the latest.\u001b[39;00m\n\u001b[1;32m    491\u001b[0m     \u001b[39mif\u001b[39;00m is_torch_tpu_available():\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages/transformers/trainer.py:3259\u001b[0m, in \u001b[0;36mTrainer.init_git_repo\u001b[0;34m(self, at_init)\u001b[0m\n\u001b[1;32m   3257\u001b[0m     repo_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mhub_model_id\n\u001b[1;32m   3258\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m repo_name:\n\u001b[0;32m-> 3259\u001b[0m     repo_name \u001b[39m=\u001b[39m get_full_repo_name(repo_name, token\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mhub_token)\n\u001b[1;32m   3261\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   3262\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrepo \u001b[39m=\u001b[39m Repository(\n\u001b[1;32m   3263\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39moutput_dir,\n\u001b[1;32m   3264\u001b[0m         clone_from\u001b[39m=\u001b[39mrepo_name,\n\u001b[1;32m   3265\u001b[0m         use_auth_token\u001b[39m=\u001b[39muse_auth_token,\n\u001b[1;32m   3266\u001b[0m         private\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mhub_private_repo,\n\u001b[1;32m   3267\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages/transformers/utils/hub.py:801\u001b[0m, in \u001b[0;36mget_full_repo_name\u001b[0;34m(model_id, organization, token)\u001b[0m\n\u001b[1;32m    799\u001b[0m     token \u001b[39m=\u001b[39m HfFolder\u001b[39m.\u001b[39mget_token()\n\u001b[1;32m    800\u001b[0m \u001b[39mif\u001b[39;00m organization \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 801\u001b[0m     username \u001b[39m=\u001b[39m whoami(token)[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00musername\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mmodel_id\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    803\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages/huggingface_hub/hf_api.py:676\u001b[0m, in \u001b[0;36mHfApi.whoami\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwhoami\u001b[39m(\u001b[39mself\u001b[39m, token: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict:\n\u001b[1;32m    666\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[39m    Call HF API to know \"whoami\".\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39m            not provided.\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     r \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(\n\u001b[1;32m    675\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendpoint\u001b[39m}\u001b[39;00m\u001b[39m/api/whoami-v2\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m--> 676\u001b[0m         headers\u001b[39m=\u001b[39mbuild_hf_headers(\n\u001b[1;32m    677\u001b[0m             \u001b[39m# If `token` is provided and not `None`, it will be used by default.\u001b[39;49;00m\n\u001b[1;32m    678\u001b[0m             \u001b[39m# Otherwise, the token must be retrieved from cache or env variable.\u001b[39;49;00m\n\u001b[1;32m    679\u001b[0m             use_auth_token\u001b[39m=\u001b[39;49m(token \u001b[39mor\u001b[39;49;00m \u001b[39mTrue\u001b[39;49;00m),\n\u001b[1;32m    680\u001b[0m         ),\n\u001b[1;32m    681\u001b[0m     )\n\u001b[1;32m    682\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    683\u001b[0m         hf_raise_for_status(r)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages/huggingface_hub/utils/_headers.py:115\u001b[0m, in \u001b[0;36mbuild_hf_headers\u001b[0;34m(use_auth_token, is_write_action, library_name, library_version, user_agent)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39mBuild headers dictionary to send in a HF Hub call.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m        If `use_auth_token=True` but token is not saved locally.\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39m# Get auth token to send\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m token_to_send \u001b[39m=\u001b[39m get_token_to_send(use_auth_token)\n\u001b[1;32m    116\u001b[0m _validate_token_to_send(token_to_send, is_write_action\u001b[39m=\u001b[39mis_write_action)\n\u001b[1;32m    118\u001b[0m \u001b[39m# Combine headers\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/fastai/lib/python3.10/site-packages/huggingface_hub/utils/_headers.py:147\u001b[0m, in \u001b[0;36mget_token_to_send\u001b[0;34m(use_auth_token)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m use_auth_token \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[39mif\u001b[39;00m cached_token \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    148\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mToken is required (`use_auth_token=True`), but no token found. You\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m need to provide a token or be logged in to Hugging Face with\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    150\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m `huggingface-cli login` or `notebook_login`. See\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    151\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m https://huggingface.co/settings/tokens.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    152\u001b[0m         )\n\u001b[1;32m    153\u001b[0m     \u001b[39mreturn\u001b[39;00m cached_token\n\u001b[1;32m    155\u001b[0m \u001b[39m# Case implicit use of the token is forbidden by env variable\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: Token is required (`use_auth_token=True`), but no token found. You need to provide a token or be logged in to Hugging Face with `huggingface-cli login` or `notebook_login`. See https://huggingface.co/settings/tokens."
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    " \n",
    "repo_name = \"finetuning-sentiment-model-3000-samples\"\n",
    " \n",
    "training_args = TrainingArguments(\n",
    "   output_dir=repo_name,\n",
    "   learning_rate=2e-5,\n",
    "   per_device_train_batch_size=16,\n",
    "   per_device_eval_batch_size=16,\n",
    "   num_train_epochs=2,\n",
    "   weight_decay=0.01,\n",
    "   save_strategy=\"epoch\",\n",
    "   push_to_hub=True,\n",
    ")\n",
    " \n",
    "trainer = Trainer(\n",
    "   model=model,\n",
    "   args=training_args,\n",
    "   train_dataset=tokenized_train,\n",
    "   eval_dataset=tokenized_test,\n",
    "   tokenizer=tokenizer,\n",
    "   data_collator=data_collator,\n",
    "   compute_metrics=compute_metrics,yn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('fastai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b6371f9b180b180e3c0fc2dc539c52593b72b3e75aed3593bd0a5845eb81bd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
